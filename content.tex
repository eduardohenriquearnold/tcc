\begin{resumo}
asd
\end{resumo}

\begin{chave}
Chaves
\end{chave}

\begin{abstract}
This paper describes the development of an industrial safety system that requires automatic human detection. Two solutions based on top-view depth images are presented. The first one is based on traditional learning techniques using feature extraction and a Support Vector Machine classifier. The second solution uses deep learning methods for classification. The performance analysis of both solutions revealed that the deep learning methods outperform traditional learning techniques on this task, at the cost of requiring a larger training set and increased computational complexity.
\end{abstract}

\begin{keywords}
  Human detection, depth images, deep learning, SVM, machine learning, computer vision.
\end{keywords}

\section{Introdução}
  Em qualquer ambiente industrial a segurança dos funcionários deve ser garantida. Existem áreas que o oferecem maior risco e portanto não devem ser ocupadas durante a operação regular. Um exemplo ilustrativo é de uma fábrica de eletrodomésticos que utiliza uma ponte rolante superior a zona de trabalho para transportar moldes de ferro até as máquinas de extrusão de plástico. Esses moldes podem ser pesados e portanto oferecem riscos aos empregados trabalhando sob o chão da fábrica.

  Nesse contexto é útil ter um sistema de segurança automático que detecte pessoas sob o caminho da ponte e interrompa sua movimentação caso encontre uma pessoa. Uma solução baseadoa em vídeo é ideal nesse caso, especialmente considerando que o ambiente indústrial em questão é diversificadamente ocupado por máquinas, moldes e trabalhadores. Como a ponte se movimenta a câmera deve ser colocada em sua parte inferior, tendo uma vista superior do chão da fábrica. Essas condições impedem que métodos de subtração de fundo \textit{background subtraction} sejam utilizados, sendo necessário utilizar algoritmos de detecção mais sofisticados.

  Outro desafio é que as roupas dos trabalhadores não são regulares em cor, e os mesmos não necessariamente usam capacetes ou equipamentos de segurança. Nesse caso utilizar apenas imagens de cor pode não fornecer informações suficientes para detecção. A fim de superar esse problema, \cite{rauter} usa uma câmera stereo que provê imagens de profundidade dos objetos, oferecendo maior confiabilidade nas informação de forma e maior invariância à luminosidade. Essa imagem é então usada para localizar candidatos à pessoas, seguido por uma extração de características desenvolvida manualmente e posterior classificação utilizando Support Vector Machine (SVM). Entretanto, esse método pode não oferecer uma solução ideal explicitadas as considerações sobre o ambiente, visto que assume-se um ambiente limpo e estático, contrário ao ambiente industrial descrito anteriormente.

  Recentemente o aumento do poder computacional, especialmente na forma de GPUs, a disponibilização de grandes datasets de imagens e avanços em métodos de treinamento \cite{nair2010relu}, em conjunto com estruturas densas de rede \cite{NIPS2013_5207} tornou possível um rápido desenvolvimento e uso de métodos profundos de aprendizado nos mais diversos domínios, inclusive ultrapassando resultados anteriores do estado-da-arte \cite{hintonCONVNET}. A grande vantagem desses métodos é a mudança de foco da representação de características das amostras, desenvolvida manualmente até então, para um processo automático de representação, requerendo grande quantidade de amostras para oferecer um modelo adequado. Motivado por esses avanços, um segundo método de detecção de pessoas pode ser desenvolvido utilizando imagens de profundidade e classificadores profundos.

  Esse trabalho faz uma comparação entre dois métodos de detecção de pessoas, ilustrado na Figura \ref{fig:system-diagram}. Ambos utilizam técnicas de visão computacional para detectar candidatos na imagem, descritas na Seção \ref{sec:candidates}. A primeira solução, baseada em \cite{rauter}, é apresentada na Seção \ref{sec:classical}, enquanto a segunda, utilizando classificadores profundos, é descrita na Seção \ref{sec:deep}. A avaliação quantitativa dos métodos e suas variações é mostrada na Seção \ref{sec:results}. Por fim, conclusões e sugestões de trabalhos futuros são apresentadas na Seção \ref{sec:conclusion}.

  \begin{figure*}[!t]
  \centering
  \includegraphics[width=\linewidth]{system-diagram.png}
  \caption{Diagrama do sistema de detecção de pessoas.}
  \label{fig:system-diagram}
  \end{figure*}

\section{Seleção de candidatos}
\label{sec:candidates}

    Em um método tradicional de detecção de objetos \cite{traditional-objdetect} o primeiro passo é localizar os candidatos, que são em seguida validados através do processo conjunto de extração de características e classificação. No caso de uma imagem colorida, uma possibilidade para obter candidatos seria utilizar uma janela de tamanho variável que se desloca sob a imagem.

    Entretanto, ao se utilizar imagens de profundidade com visão superior, \cite{rauter} sugere um algoritmo mais eficiente que assume que as pessoas estão entre os objetos mais altos da cena. Apesar dessa hipótese nem sempre ser garantida, ela reduz significantemente o número de candidatos se comparado com o método das janelas deslocadas, e portanto será utilizada nesse trabalho e descrita a seguir.

    Primeiramente, realiza-se uma operação de máximos locais. Divide-se a imagem em blocos de tamanho especificicado e cada bloco retorna o pixel com maior intensidade, representando o ponto mais alto naquele bloco. Em seguida, para cada máximo local uma janela quadrada representando o candidato precisa ser obtida. Seu tamanho é calculado como
    \begin{equation}
      s_w = \frac{f}{d} \cdot s_r
    \end{equation}
    onde $f$ é a distância focal da câmera, $d$ a distância entre a câmera e o objeto e $s_r$ o tamanho médio da cabeça. A janela de tamanho $s_w$ pixels é centralizada em torno do respectivo pixel de máximo local.

    O último passo é a centralização da janela sob o candidato utilizando um algoritmo iterativo de \textit{mean shift}. De forma simplificada, esse algoritmo desloca a janela para o centróide dos pixels dentro dela, de forma que pixels de maior intensidade tenderão a ficar centralizados sob o candidato.

    A saída desse passo é uma lista de janelas representando os candidatos à pessoas na imagem. Um aspecto relevante a se considerar é o parâmetro de tamanho dos blocos para efetuar a busca de máximos locais. Quando se utiliza blocos muito grandes a probabilidade de ter um objeto muito alto, como uma máquina, no mesmo bloco que uma pessoa é alta, portanto aumenta-se as chances de falha de detecção. Por outro lado, quando se utiliza um bloco muito pequeno, é garantido que todas as pessoas serão consideradas candidatas, porém ao mesmo tempo eleva-se muito o número de candidatos, o que ocasiona um problema de complexidade e de performance temporal, dado que esses candidatos precisam ainda passar por validação.

\section{Solução clássica baseada em extração de características manual}
\label{sec:classical}

    Após a detecção de candidatos uma fase de validação é necessária para descartar candidatos que não são pessoas. Uma solução clássica utilizando visão computacional \cite{rauter} utiliza características extraídas por um descritor, desenvolvido manualmente, para alimentar um classificador SVM binário, que retorna uma classe: ``pessoa'' ou ``não-pessoa''. Um descritor de blocos regulares proposto em \cite{rauter} é utilizado. Para aumentar a invariância à rotação, também propomos um descritor de anéis concêntricos (veja Figura \ref{fig:descriptors}). Ambos são descritos a seguir, seguidos por mais detalhes do processo de classificação e treinamento.

    \begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{tradicional/descritores}
    \caption{Descritor de grades regulares (esquerda) and anéis concêntricos (direita).}
    \label{fig:descriptors}
    \end{figure}

    \subsection{Descritor de grades regulares}
      Esse descritor divide a janela do candidato em 7x7 blocos, como ilustra a Figura \ref{fig:descriptors}. O valor médio dos pixels pertencentes à cada bloco é calculado, gerando uma matriz 7x7 de médias de intensidades de pixels. Em seguida, o valor do bloco central é subtraído da matriz. Finalmente, calcula-se o histograma da matriz resultante utilizando 32 intervalos. O vetor de histograma, com 32 dimensões, é considerado o vetor de descrição, cuja soma é 49 (número de blocos).

    \subsection{Descritor de anéis concêntricos}
       Primeiramente a janela do candidato é dividida em 18 coroas circulares (ou anéis) cujas distâncias entre os raios internos e externos é constante e cujo centro coincide com o da janela. Então calcula-se a média dos pixels pertences a cada coroa, resultando num vetor de 18 dimensões. Desse vetor subtrai-se o valor da média dos pixels da coroa mais interna (cujo raior menor é 0). Por fim, aplica-se a derivada discreta nesse vetor (subtração entre dimensões adjacentes) a fim de enunciar as diferenças entre as médias do pixels nos diferentes anéis, resultando num vetor de descrição com 17 dimensões.

    \subsection{Classificador SVM}
      Utiliza-se um classificador SVM binário com kernel \textit{Radial Basis Function (RBF)} \cite{rbfkernel} para validar os candidatos. Note que o parâmetro $\sigma$ do kernel, em conjunto com o hiper-parâmetro $C$ do SVM controlam o compromisso entre o desempenho no treinamento e a generalização do modelo em novas amostras. Valores altos de $C$ penalizam erros no conjunto de treinamento, enquanto valores menores priorizam um desempenho melhor no conjunto de teste. O parâmetro $\sigma$ tem efeito similar, porém de maneira inversa.

      A escolha dos hiper-parâmetros $C$ e $\sigma$ é feita utilizando um processo de validação cruzada com 5 conjuntos, avaliando a métrica de precisão \cite{evaluationMetrics}. Depois desse processo uma etapa de treinamento utilizando todo o conjunto de treinamento, composto de 9894 amostras negativas e 1222 positivas, é realizado. O conjunto de dados foi gerado por amostras de vídeo coletadas na fábrica durante um experimento para testar posições da câmera (fixada em uma altura de 6m). Cada amostra nesse conjunto é um recorte da janela do candidato sob a imagem de profundidade. Esses recortes foram manualmente classificados como positivos (pessoa) ou negativos (não-pessoa). O classificador SVM foi implementado em Python utilizando o toolkit Scikit-learn \cite{scikit-learn}.


\section{Deep learning based solution}
\label{sec:deep}

    Neural networks can be used to perform robust classification with complexity varying according to the network structure and depth. We use and evaluate two deep structures: multilayer perceptron (MLP) and convolutional neural networks (CNN). In our solution for both approaches, the candidate is resized to a 60x60 window and directly fed to the classifier, without any feature-extraction process. We can consider that the model itself will encode a feature set in the first layers of the network, with the final layer doing the classification process and outputing a single probability of that candidate being a human. The diagram would be the same as presented in Figure \ref{fig:system-diagram} without the feature extraction block and with a real valued output probability.

    \subsection{Multilayer perceptron}toolkit
        The MLP structure is composed by units organized in layers. Every unit in a single layer is connected to every unit on the following layer. Each unit calculates its output by summing of its inputs, weigthed by the connections parameters, and then applying an activation function $\phi(x)$. Each output is forward propagated through the network from the input layers, through the hidden layers until the output layer.

        We use a structure with 3600 input units (60x60 pixels), 512 and 256 units in the hidden layers and a single unit in the output layer, as seen in Figure \ref{fig:diag-mlp}. The hidden layers, shown in yellow, use the RELU \cite{nair2010relu} activation function to avoid the vanishing gradient problem. The single output unit uses a sigmoid activation function to reproduce a probabilistic output.

        \begin{figure}
        \centering
        \includegraphics[width=0.8\linewidth]{diagram/diag-mlp.png}
        \caption{MLP network structure.}
        \label{fig:diag-mlp}
        \end{figure}

    \subsection{Convolutional neural network}
         In images there are strong local correlation of pixels, so it is not necessary that every unit in each layer is connected to every unit in the following layer, but just to a few local neighbours. This local connectivity is achieved through the convolution of a given layer with a bank of filters. In this sense, convolutional neural networks are a derivation of MLP and, in general, give a better model for images by reducing the number of parameters thus helping to generalize.

        Our CNN structure, depicted in Figure \ref{fig:diag-cnn}, is composed by a 3x3 convolution layer with 16 feature maps (filters), followed by a 3x3 max pooling layer, then flattening resulting in 5776 (16x19x19) units followed by a 128-units dense layer to perform classification, and finally by a single output unit that gives a probabilistic output. Again, the hidden layers use RELU activation and the output unit uses sigmoid activation.

        \begin{figure}
        \centering
        \includegraphics[width=0.9\linewidth]{diagram/diag-cnn.png}
        \caption{CNN network structure.}
        \label{fig:diag-cnn}
        \end{figure}

    \subsection{Implementation}
        The training process consists of minimizing an objective function, in this case, the binary cross-entropy function \cite{DLbook}, also known as logloss. Its use is justified by the probabilistic nature of the output layer. The optimization method used is a variation of Batch Stochastic Gradient Descent (B-SGD) called Adam \cite{kingma2014adam}, which uses an adaptive learning rate based on momentum considerations (gradient based) for each parameter.

        Since deep models require a larger training set, we extended the SVM training set to 16898 samples, from which 14966 are negative. A challenge faced during the training phase was the impossibility of getting a coherent model due to the unbalanced distribution of the dataset: more than 88\% of the samples belonged to the negative class, so the model would classify all the samples as negative and still get a relative high accuracy. To overcome this, we artificially balanced our training set by replicating positive samples until their frequency was the same as the negative class.

        The computer vision task, candidate extraction, resizing, was done in C++ with the OpenCV library. The deep classifier was implemented using Keras \cite{keras} on top of Theano \cite{theano}, allowing GPU acceleration and enabling a fast training process (an epoch per minute).


\section{Results}
\label{sec:results}

    The evaluation uses Receiver Operating Characteristic (ROC) curves \cite{evaluationMetrics} to compare between solutions and parameters. These curves are generated from the probabilistic output of the classifiers used. In the case of SVM which under original formulations is a non-probabilistic classifier, we use a logistic regression formulation \cite{svmProbabilisticOutput} to enable a probabilistic output. The advantage of using such a probabilistic output classifier is the possibility of adjusting the true-positive vs false-positive tradeoff even after training, by choosing the probability threshold above which the sample is considered to be positive.

    To evaluate the solutions proposed on Sections \ref{sec:classical} and \ref{sec:deep}, with their variations, we firstly consider the candidates already extracted from a video sequence, which will be called the test set, thus evaluating only the descriptor and classifier. Figure \ref{fig:result-classifiers} shows the performance of the classifiers under the test set and a Area Under Curve (AUC) score \cite{evaluationMetrics} (measured up to 10\% of false-positive rate). We can clearly see that deep based classifiers outperform the traditional hand-engineered feature extraction based approach. Although both MLP and CNN perform similarly, one of them can be chosen depending upon the desired region of operation (higher true-positive rate or lower false-positive rate).

    \begin{figure*}[!t]
    \centering
    \subfloat[]{\includegraphics[width=0.45\linewidth]{results/ROC_all.pdf}}%
    \label{fig:result-classifiers-all}
    \hfil
    \subfloat[10 \% interest zone]{\includegraphics[width=0.45\linewidth]{results/ROC_all_zoom.pdf}}%
    \label{fig:result-classifiers-all-zoom}
    \caption{Classifiers performance.}
    \label{fig:result-classifiers}
    \end{figure*}

    In a second phase we consider the overall system performance, including the candidate extraction step. It is important to note that the performance observed in Figure \ref{fig:result-classifiers} is an upper bound of the overall performance, since now there will be miss-detections from the candidate extraction step. Another consideration is that in this phase the test set is composed of entire frames, so the probability of the frame contain at least one head could be calculated using
    \begin{equation}
    P[y=1] = 1 - \prod_i^n (1-p_i)
    \end{equation}
    where $y$ is a random variable valued 1 if there are humans in the scene or 0 otherwise, $n$ is the number of candidates and $p_i$ is the classifier output of candidate $i$. Figure \ref{fig:result-system} shows the overall system performance using this formulation with the combinations of MLP and CNN classifiers with coarse and fine scales of candidate extraction windows.

    The results show that on a coarse scale detector, the MLP and CNN classifiers have similar performance, because the candidates that get extracted have similar outputs. However, on a fine scale detector, many more candidates are detected so there are more samples to explore the performances of the two classifiers, showing how the CNN model outperforms MLP.

    \begin{figure*}[!t]
    \centering
    \subfloat[]{\includegraphics[width=0.45\linewidth]{results/ROC_system.pdf}}%
    \label{fig:result-system-all}
    \hfil
    \subfloat[10 \% interest zone, best results]{\includegraphics[width=0.45\linewidth]{results/ROC_system_zoom_best.pdf}}%
    \label{fig:result-system-all-zoom}
    \caption{Overall system performance.}
    \label{fig:result-system}
    \end{figure*}

\section{Conclusion}
\label{sec:conclusion}

    This paper investigates two solutions for the human detection problem, one based on traditional computer vision methods and another on deep learning techniques. The results presented in Section \ref{sec:results} show that the last method outperforms traditional hand-engineered feature extraction and classification, although they require a larger training set and have higher complexity, thus requiring more processing power. While deep learning techniques are widely regarded as useful for big datasets, we were still able to achieve good performance, even under a moderate-sized unbalanced dataset.

    One possible direction of future work is investigating a more general CNN structure. Instead of receiving just the candidate window, it would receive the whole depth frame as input and output the probability that frame contains a human. As we saw an improvement of the classification by letting the model choose the best representation of the data, we suspect that allowing the model to access the whole frame as opposed to only small windows possibly containing humans will improve the overall system performance.
